{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RECORDINGS_FOLDER = os.path.join('..', '..', 'recordings')\n",
    "\n",
    "RECORDINGS_TRAIN = {\n",
    "    # 'left-02.csv', \n",
    "#     'left': ['left-01.csv', 'left-02.csv'],\n",
    "#     'right': ['right-01.csv', 'right-02.csv'], #, 'right-03.csv'],\n",
    "#     'lr': ['left-01.csv', 'left-02.csv', 'right-01.csv', 'right-03.csv'],\n",
    "      'relaxed': ['closed-relax-01.csv', 'closed-relax-02.csv'],\n",
    "#     'forward': ['forward-01.csv'],  # TODO(andrei): Maybe 'run-01-andrei.csv'.\n",
    "#     'helicopter': ['helicopter-andrei.csv'],\n",
    "      'baseline': ['baseline-andrei.csv', 'internet-browsing-01.csv'],\n",
    "      'tense': ['typingtest-01.csv', 'typingtest-03.csv']\n",
    "}\n",
    "\n",
    "RECORDINGS_VALID = {\n",
    "#     'lr': ['right-03.csv', 'left-03.csv'],\n",
    "#     'right': [],\n",
    "#     'forward': [],\n",
    "#     'helicopter': [],\n",
    "#     'baseline': ['internet-browsing-01.csv']\n",
    "    'relaxed': [],\n",
    "    'tense': ['typingtest-02.csv'],\n",
    "    'baseline': []\n",
    "}\n",
    "\n",
    "\n",
    "MUSE_LABELS = {\n",
    " '/muse/acc',\n",
    " '/muse/batt',\n",
    " '/muse/config',\n",
    " '/muse/drlref',\n",
    " '/muse/eeg',\n",
    " '/muse/eeg/quantization',\n",
    " '/muse/elements/alpha_absolute',\n",
    " '/muse/elements/alpha_relative',\n",
    " '/muse/elements/alpha_session_score',\n",
    " '/muse/elements/beta_absolute',\n",
    " '/muse/elements/beta_relative',\n",
    " '/muse/elements/beta_session_score',\n",
    " '/muse/elements/blink',\n",
    " '/muse/elements/delta_absolute',\n",
    " '/muse/elements/delta_relative',\n",
    " '/muse/elements/delta_session_score',\n",
    " '/muse/elements/experimental/concentration',\n",
    " '/muse/elements/experimental/mellow',\n",
    " '/muse/elements/gamma_absolute',\n",
    " '/muse/elements/gamma_relative',\n",
    " '/muse/elements/gamma_session_score',\n",
    " '/muse/elements/horseshoe',\n",
    " '/muse/elements/is_good',\n",
    " '/muse/elements/jaw_clench',\n",
    " '/muse/elements/low_freqs_absolute',\n",
    " '/muse/elements/raw_fft0',\n",
    " '/muse/elements/raw_fft1',\n",
    " '/muse/elements/raw_fft2',\n",
    " '/muse/elements/raw_fft3',\n",
    " '/muse/elements/theta_absolute',\n",
    " '/muse/elements/theta_relative',\n",
    " '/muse/elements/theta_session_score',\n",
    " '/muse/elements/touching_forehead',\n",
    " '/muse/version'}\n",
    "\n",
    "# 4 electrodes, 4 sets of FFT coefficients per window!\n",
    "RAW_FFT0 = '/muse/elements/raw_fft0'\n",
    "RAW_FFT1 = '/muse/elements/raw_fft1'\n",
    "RAW_FFT2 = '/muse/elements/raw_fft2'\n",
    "RAW_FFT3 = '/muse/elements/raw_fft3'\n",
    "IS_GOOD = '/muse/elements/is_good'\n",
    "# interesting_feats = ['/muse/elements/raw_fft0', 'alpha_absolute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_rec(fpath: str):\n",
    "    all_ts = []\n",
    "    all_fft = []\n",
    "    all_good_masks = []\n",
    "    \n",
    "    # TODO(andrei): the IS_GOOD may contain too little info, maybe. Should try horseshoe and a thresh of like <1.25 or so.\n",
    "    \n",
    "    last_good = [0, 0, 0, 0]\n",
    "    last_good_time = -1\n",
    "    \n",
    "    current_feat = None\n",
    "    \n",
    "    # We expect fft indices always in 0-1-2-3 order. This variable keeps track of this.\n",
    "    expecting = 0\n",
    "    \n",
    "    with open(fpath, 'r') as f:\n",
    "        for line_idx, line in enumerate(f.readlines()):            \n",
    "            parts = line.split(', ')\n",
    "            ts = float(parts[0])\n",
    "            label = parts[1]\n",
    "            \n",
    "            if label.startswith('/muse/elements/raw_fft'):\n",
    "                rest_np = np.array([float(part) for part in parts[2:]])\n",
    "                idx = int(label[-1])\n",
    "                if idx != expecting:\n",
    "                    print(\"WRONG\")\n",
    "                    raise ValueError();\n",
    "                else:\n",
    "                    if current_feat is None:\n",
    "                        current_feat = rest_np\n",
    "                    else:\n",
    "                        current_feat = np.hstack((current_feat, rest_np))\n",
    "                    \n",
    "                    expecting = (idx + 1) % 4\n",
    "                    \n",
    "                    if expecting == 0:\n",
    "                        if last_good_time != -1 and (ts - last_good_time) > 0.005 and (ts - last_good_time) > 0.00:\n",
    "                            print(\"WARNING: Bad data sync.\")\n",
    "                  \n",
    "                        all_ts.append(ts)\n",
    "                        all_fft.append(current_feat)\n",
    "                        all_good_masks.append(np.all(last_good))\n",
    "#                         print('cfs', current_feat.shape)\n",
    "                        current_feat = None\n",
    "  \n",
    "            \n",
    "#             if label == RAW_FFT0:\n",
    "\n",
    "#                 all_fft.append(rest_np)\n",
    "#                 all_fft1.append(last_fft1)\n",
    "#                 all_good_masks.append(np.all(last_good))\n",
    "                  \n",
    "#                 # TODO(andrei): WARNING, this tolerance is HUGE, so may be problematic.\n",
    "#                 if last_fft1_time != -1 and (ts - last_fft1_time) > 0.18 and (ts - last_fft1_time) > 0.00:\n",
    "#                     print(\"WARNING: Bad data sync (fft1).\", ts - last_fft1_time)\n",
    "#             elif label == RAW_FFT1:\n",
    "#                 last_fft1_time = ts\n",
    "#                 rest_np = np.array([float(part) for part in parts[2:]])\n",
    "#                 if(rest_np.shape != (129,)):\n",
    "#                     print(\"WTF:\", rest_np.shape)\n",
    "#                 last_fft1 = rest_np\n",
    "            elif label == IS_GOOD:\n",
    "                last_good_time = ts\n",
    "                rest_np = np.array([float(part) for part in parts[2:]])\n",
    "                last_good = rest_np\n",
    "                \n",
    "#     print(len(all_fft))\n",
    "#     print(len(all_fft1))\n",
    "#     print(len(all_fft[0]))\n",
    "#     print(len(all_fft1[0]))\n",
    "#     print(np.array(all_fft).shape)\n",
    "#     print(np.array(all_fft1).shape)\n",
    "\n",
    "    print(len(all_fft))\n",
    "    print(np.array(all_fft).shape)\n",
    "    return np.array(all_good_masks), np.array(all_ts), np.array(all_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train...\n",
      "1368\n",
      "(1368, 516)\n",
      "(1368, 516) (1368,)\n",
      "1881\n",
      "(1881, 516)\n",
      "(1881, 516) (1881,)\n",
      "1235\n",
      "(1235, 516)\n",
      "(1235, 516) (1235,)\n",
      "1079\n",
      "(1079, 516)\n",
      "(1079, 516) (1079,)\n",
      "WARNING: Bad data sync.\n",
      "WARNING: Bad data sync.\n",
      "WARNING: Bad data sync.\n",
      "WARNING: Bad data sync.\n",
      "WARNING: Bad data sync.\n",
      "WARNING: Bad data sync.\n",
      "WARNING: Bad data sync.\n",
      "WARNING: Bad data sync.\n",
      "WARNING: Bad data sync.\n",
      "WARNING: Bad data sync.\n",
      "WARNING: Bad data sync.\n",
      "WARNING: Bad data sync.\n",
      "WARNING: Bad data sync.\n",
      "WARNING: Bad data sync.\n",
      "WARNING: Bad data sync.\n",
      "WARNING: Bad data sync.\n",
      "WARNING: Bad data sync.\n",
      "1806\n",
      "(1806, 516)\n",
      "(1806, 516) (1806,)\n",
      "WARNING: Bad data sync.\n",
      "WARNING: Bad data sync.\n",
      "1996\n",
      "(1996, 516)\n",
      "(1996, 516) (1996,)\n",
      "tense: (2878, 516)\n",
      "relaxed: (2304, 516)\n",
      "baseline: (2764, 516)\n",
      "Processing validation...\n",
      "1895\n",
      "(1895, 516)\n",
      "(1895, 516) (1895,)\n",
      "tense: (45, 516)\n",
      "relaxed: (0,)\n",
      "baseline: (0,)\n"
     ]
    }
   ],
   "source": [
    "def spec2data(recording_map):\n",
    "    data_map = {}\n",
    "    for label, fnames in recording_map.items():\n",
    "        cfeats = []\n",
    "        for fname in fnames:\n",
    "            # Read the data for that recording for that \n",
    "            good_mask, all_ts, all_feats = read_rec(os.path.join(RECORDINGS_FOLDER, fname))\n",
    "    #         all_ts = all_ts[good_mask]\n",
    "            print(all_feats.shape, good_mask.shape)\n",
    "            all_feats = all_feats[good_mask]\n",
    "            cfeats.append(all_feats)\n",
    "\n",
    "        if len(cfeats) > 1:\n",
    "            data_map[label] = np.vstack(cfeats)\n",
    "        elif len(cfeats) == 1:\n",
    "            data_map[label] = cfeats[0]\n",
    "        else:\n",
    "            data_map[label] = np.array([])\n",
    "    \n",
    "    for label, data in data_map.items():\n",
    "        print(\"{0}: {1}\".format(label, data.shape))\n",
    "        \n",
    "    return data_map\n",
    "\n",
    "print(\"Processing train...\")\n",
    "data_map_train = spec2data(RECORDINGS_TRAIN)\n",
    "print(\"Processing validation...\")\n",
    "data_map_test = spec2data(RECORDINGS_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tense\n",
      "1 relaxed\n",
      "2 baseline\n",
      "0 tense\n"
     ]
    }
   ],
   "source": [
    "def gen_data_matrix(data_map):\n",
    "    X = None\n",
    "    y = None\n",
    "\n",
    "    for idx, (label, data) in enumerate(data_map.items()):\n",
    "        if len(data) == 0:\n",
    "            continue\n",
    "            \n",
    "        print(idx, label)\n",
    "            \n",
    "        if X is None:\n",
    "            X = data\n",
    "            y = np.zeros(X.shape[0])\n",
    "        else:\n",
    "            X = np.vstack((X, data))\n",
    "            y = np.hstack((y, np.ones(data.shape[0]) * idx))\n",
    "\n",
    "#     print(X.shape)\n",
    "#     print(y.shape)\n",
    "    return X, y\n",
    "    \n",
    "X_train, y_train = gen_data_matrix(data_map_train)\n",
    "X_test, y_test = gen_data_matrix(data_map_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all_ts_run = np.array(all_ts_run)\n",
    "# deltas = all_ts_run[1:] - all_ts_run[:-1]\n",
    "# print(deltas.mean())\n",
    "# print(np.median(deltas))\n",
    "# print(deltas.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7946, 516) (7946,)\n",
      "float64 float64\n"
     ]
    }
   ],
   "source": [
    "# X_train = np.vstack((all_fft_base, all_fft_run))\n",
    "# y_train = np.hstack((np.zeros(all_fft_base.shape[0]), np.ones(all_fft_run.shape[0])))\n",
    "# X_train = np.vstack((all_fft_heli, all_fft_run, all_fft_base))\n",
    "# y_train = np.hstack((np.zeros(all_fft_heli.shape[0]), np.ones(all_fft_run.shape[0]), 2 * np.ones(all_fft_base.shape[0])))\n",
    "\n",
    "# print(all_fft_base.shape, all_fft_run.shape, all_fft_heli.shape)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_train.dtype, y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=lambda x: x[1], reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"{2}: Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores),\n",
    "              i + 1))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2878    0    0    0    0 2304    0    0    0 2764]\n",
      "(7946, 516)\n",
      "Kicking off grid search...\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done  36 tasks      | elapsed:   59.5s\n",
      "[Parallel(n_jobs=-2)]: Done  60 out of  60 | elapsed:  1.6min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.pipeline import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import *\n",
    "\n",
    "# clf = DummyClassifier()\n",
    "clf = RandomForestClassifier()\n",
    "# clf = SVC()\n",
    "clf = LogisticRegression()\n",
    "\n",
    "Cs = [0.01, 0.1, 1.0, 2.0, 10, 25]\n",
    "# tuned_parameters = [{'kernel': ['rbf'], 'gamma': [0.1, 0.01, 0.001, 0.0001],\n",
    "#                      'C': [0.001, 0.01, 0.1, 0.5, 1, 5, 10, 25, 50]},\n",
    "#                     {'kernel': ['linear'], 'C': [0.001, 0.01, 0.05, 0.1, 0.5, 10, 50, 100]}]\n",
    "# cws = ['balanced', {0: 3, 1: 1}, {0: 1, 1: 1}]\n",
    "tuned_parameters = [ # SVC\n",
    "#     {\n",
    "#         'clf__kernel': ['linear'],\n",
    "#         'clf__C': Cs,\n",
    "#     },\n",
    "    {\n",
    "        'clf__kernel': ['rbf'],\n",
    "        'clf__gamma': [0.1, 0.01, 0.001], #, 0.0001],\n",
    "        'clf__C': Cs,\n",
    "#         'epsilon': []\n",
    "    },\n",
    "#     {\n",
    "# #         'kernel': ['poly']\n",
    "#     }\n",
    "]\n",
    "tuned_parameters = {\n",
    "    'clf__n_estimators': [2, 3, 5, 10], #, 15, 20], #, 25, 50], #, 75, 100, 125]#, 150],\n",
    "    'clf__class_weight': ['balanced'],\n",
    "#     'scaler__with_mean': [True, False],\n",
    "#     'scaler__with_std': [True, False],\n",
    "}\n",
    "\n",
    "tuned_parameters = { # LogReg\n",
    "    'clf__C': [0.01, 0.1, 0.25, 1.0, 2.5, 5.0],\n",
    "#     'scaler__with_mean': [True, False],\n",
    "#     'scaler__with_std': [True, False],\n",
    "}\n",
    "# tuned_parameters = { }\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "print(np.histogram(y_train)[0])\n",
    "grid = GridSearchCV(pipeline, tuned_parameters, cv=10, scoring='f1_macro', n_jobs=-2, verbose=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(\"Kicking off grid search...\")\n",
    "\n",
    "# Hack to suppress tons of output when doing feature selection (doesn't impact the actual feature selection)\n",
    "# np.seterr(all='ignore')\n",
    "res = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Mean validation score: 0.881 (std: 0.050)\n",
      "Parameters: {'scaler__with_std': True, 'clf__C': 0.001, 'scaler__with_mean': True}\n",
      "2: Mean validation score: 0.880 (std: 0.040)\n",
      "Parameters: {'scaler__with_std': True, 'clf__C': 0.005, 'scaler__with_mean': True}\n",
      "3: Mean validation score: 0.880 (std: 0.046)\n",
      "Parameters: {'scaler__with_std': True, 'clf__C': 0.001, 'scaler__with_mean': False}\n",
      "4: Mean validation score: 0.878 (std: 0.039)\n",
      "Parameters: {'scaler__with_std': True, 'clf__C': 0.01, 'scaler__with_mean': True}\n",
      "5: Mean validation score: 0.872 (std: 0.044)\n",
      "Parameters: {'scaler__with_std': True, 'clf__C': 0.005, 'scaler__with_mean': False}\n",
      "6: Mean validation score: 0.868 (std: 0.036)\n",
      "Parameters: {'scaler__with_std': True, 'clf__C': 0.1, 'scaler__with_mean': True}\n",
      "7: Mean validation score: 0.867 (std: 0.041)\n",
      "Parameters: {'scaler__with_std': True, 'clf__C': 0.01, 'scaler__with_mean': False}\n",
      "8: Mean validation score: 0.866 (std: 0.037)\n",
      "Parameters: {'scaler__with_std': False, 'clf__C': 0.001, 'scaler__with_mean': True}\n",
      "9: Mean validation score: 0.865 (std: 0.034)\n",
      "Parameters: {'scaler__with_std': True, 'clf__C': 0.25, 'scaler__with_mean': True}\n",
      "10: Mean validation score: 0.861 (std: 0.044)\n",
      "Parameters: {'scaler__with_std': False, 'clf__C': 0.001, 'scaler__with_mean': False}\n",
      "11: Mean validation score: 0.859 (std: 0.039)\n",
      "Parameters: {'scaler__with_std': False, 'clf__C': 0.005, 'scaler__with_mean': True}\n",
      "12: Mean validation score: 0.857 (std: 0.039)\n",
      "Parameters: {'scaler__with_std': False, 'clf__C': 0.01, 'scaler__with_mean': True}\n",
      "13: Mean validation score: 0.857 (std: 0.044)\n",
      "Parameters: {'scaler__with_std': False, 'clf__C': 0.005, 'scaler__with_mean': False}\n",
      "14: Mean validation score: 0.857 (std: 0.041)\n",
      "Parameters: {'scaler__with_std': True, 'clf__C': 0.1, 'scaler__with_mean': False}\n",
      "15: Mean validation score: 0.854 (std: 0.044)\n",
      "Parameters: {'scaler__with_std': False, 'clf__C': 0.01, 'scaler__with_mean': False}\n",
      "16: Mean validation score: 0.853 (std: 0.039)\n",
      "Parameters: {'scaler__with_std': False, 'clf__C': 0.1, 'scaler__with_mean': True}\n",
      "17: Mean validation score: 0.852 (std: 0.038)\n",
      "Parameters: {'scaler__with_std': False, 'clf__C': 0.25, 'scaler__with_mean': True}\n",
      "18: Mean validation score: 0.852 (std: 0.041)\n",
      "Parameters: {'scaler__with_std': True, 'clf__C': 0.25, 'scaler__with_mean': False}\n",
      "19: Mean validation score: 0.847 (std: 0.045)\n",
      "Parameters: {'scaler__with_std': False, 'clf__C': 0.1, 'scaler__with_mean': False}\n",
      "20: Mean validation score: 0.846 (std: 0.046)\n",
      "Parameters: {'scaler__with_std': False, 'clf__C': 0.25, 'scaler__with_mean': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrei/anaconda3/envs/oxh/lib/python3.5/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "report(res.grid_scores_, n_top=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2803,   48,   27],\n",
       "       [  26, 2278,    0],\n",
       "       [   0,   24, 2740]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = grid.predict(X_train)\n",
    "confusion_matrix(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  2.  2.  2.  2.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.\n",
      "  1.  0.  0.  0.  0.  0.  2.  2.  2.]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "yy=res.predict(X_test)\n",
    "print(yy)\n",
    "counts = np.bincount(yy.astype(np.int64))\n",
    "print(np.argmax(counts))\n",
    "# print(f1_score(y_test, yy, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=10, error_score='raise',\n",
      "       estimator=Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))]),\n",
      "       fit_params={}, iid=True, n_jobs=-2,\n",
      "       param_grid={'clf__n_estimators': [10, 15, 20, 25, 50], 'clf__class_weight': ['balanced']},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring='f1_micro', verbose=1)\n"
     ]
    }
   ],
   "source": [
    "# print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully dumped model pickle.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../model-lr.pkl', 'wb') as f:\n",
    "    pickle.dump(res.best_estimator_, f)\n",
    "    print(\"Successfully dumped model pickle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
